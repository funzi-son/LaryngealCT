{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNh10eSXlHXIB+BLD/4fsLS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["ResNet18 model for classification of T4 and Non-T4 laryngeal cancer"],"metadata":{"id":"J8tU3lw5J2Iv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5PH-8NRhJ1V3"},"outputs":[],"source":["# Install required libraries (Run once)\n","!pip install monai torch torchvision pandas openpyxl scikit-learn torchio --quiet"]},{"cell_type":"code","source":["!pip install monai==1.2.0 --quiet"],"metadata":{"id":"eA2L2eWWKNpF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Imports\n","import os, numpy as np, pandas as pd, torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n","import torchio as tio\n","import SimpleITK as sitk\n","from scipy.ndimage import zoom\n","import matplotlib.pyplot as plt\n","from monai.networks.nets import resnet18\n","\n","# Config\n","IMAGE_DIR = \"/data/cropped_nrrds\"\n","LABEL_FILE = \"/data/annotations/LaryngealCT_metadata.xlsx\"\n","OUTPUT_DIR = \"/data/resnet18_cv_results\"\n","TARGET_SHAPE = (32, 96, 96)\n","EPOCHS, PATIENCE, LR, BATCH_SIZE, FOLDS = 100, 10, 1e-4, 4, 5\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Loss\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=None, gamma=2.0):\n","        super().__init__()\n","        self.alpha = alpha.float() if alpha is not None else None\n","        self.gamma = gamma\n","    def forward(self, inputs, targets):\n","        ce = nn.functional.cross_entropy(inputs, targets, reduction='none')\n","        pt = torch.exp(-ce)\n","        if self.alpha is not None:\n","            at = self.alpha[targets]\n","            loss = at * (1 - pt) ** self.gamma * ce\n","        else:\n","            loss = (1 - pt) ** self.gamma * ce\n","        return loss.mean()\n","\n","# Dataset\n","class CTSubjectDataset(tio.SubjectsDataset):\n","    def __init__(self, df, augment=False):\n","        subjects = []\n","        for _, row in df.iterrows():\n","            path = os.path.join(IMAGE_DIR, row['Filename'])\n","            img = sitk.GetArrayFromImage(sitk.ReadImage(path)).astype(np.float32)\n","            img = np.clip(img, -300, 300)\n","            img = (img - img.mean()) / (img.std() + 1e-5)\n","            img = zoom(img, [t / s for t, s in zip(TARGET_SHAPE, img.shape)], order=1)\n","            img = np.expand_dims(img, 0)\n","            subject = tio.Subject(image=tio.ScalarImage(tensor=torch.tensor(img)), label=int(row['Label']))\n","            subjects.append(subject)\n","        transform = tio.Compose([\n","            tio.RandomAffine(scales=(0.9, 1.1), degrees=10, translation=5, p=0.7),\n","            tio.RandomElasticDeformation(num_control_points=5, max_displacement=3, p=0.5),\n","            tio.RandomGamma(log_gamma=(-0.3, 0.3), p=0.5),\n","            tio.RandomNoise(p=0.3),\n","            tio.RandomFlip(axes=('LR',), p=0.5)\n","        ]) if augment else None\n","        super().__init__(subjects, transform=transform)\n","    def __getitem__(self, i):\n","        subj = super().__getitem__(i)\n","        return subj['image'].data.float(), torch.tensor(subj['label'])\n","\n","# Model\n","class ResNet18_3D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = resnet18(spatial_dims=3, n_input_channels=1, num_classes=2, pretrained=False)\n","    def forward(self, x): return self.model(x)\n","\n","# Data\n","df = pd.read_excel(LABEL_FILE)[['Study_ID', 'Label']].dropna()\n","df['Filename'] = df['Study_ID'].astype(str) + \"_0000.nrrd\"\n","df['Label'] = df['Label'].map({'Non_T4': 0, 'T4': 1})\n","\n","# Cross-Validation Loop\n","skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n","for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['Label']), 1):\n","    print(f\"\\nüìÇ Fold {fold}\")\n","    fold_dir = os.path.join(OUTPUT_DIR, f\"fold_{fold}\")\n","    os.makedirs(fold_dir, exist_ok=True)\n","    train_df, val_df = df.iloc[train_idx], df.iloc[val_idx]\n","\n","    weights = 1. / train_df['Label'].value_counts()\n","    sampler = WeightedRandomSampler(train_df['Label'].map(weights).values, len(train_df), replacement=True)\n","\n","    train_loader = DataLoader(CTSubjectDataset(train_df, augment=True), batch_size=BATCH_SIZE, sampler=sampler)\n","    val_loader = DataLoader(CTSubjectDataset(val_df), batch_size=BATCH_SIZE)\n","\n","    model = ResNet18_3D().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","    loss_fn = FocalLoss(alpha=torch.tensor([1.0, 4.0]).to(device))\n","    metrics, best_f1, patience_counter = [], 0, 0\n","\n","    for epoch in range(1, EPOCHS + 1):\n","        model.train(); total_loss = 0\n","        for x, y in train_loader:\n","            optimizer.zero_grad()\n","            out = model(x.to(device))\n","            loss = loss_fn(out, y.to(device))\n","            loss.backward(); optimizer.step()\n","            total_loss += loss.item()\n","        train_loss = total_loss / len(train_loader)\n","\n","        model.eval(); val_loss, preds, probs, trues = 0, [], [], []\n","        with torch.no_grad():\n","            for x, y in val_loader:\n","                out = model(x.to(device))\n","                val_loss += loss_fn(out, y.to(device)).item()\n","                probs += torch.softmax(out, 1)[:, 1].cpu().tolist()\n","                preds += torch.argmax(out, 1).cpu().tolist()\n","                trues += y.tolist()\n","        val_loss /= len(val_loader)\n","\n","        report = classification_report(trues, preds, output_dict=True, zero_division=0)\n","        auc = roc_auc_score(trues, probs)\n","        row = {\n","            'epoch': epoch,\n","            'train_loss': train_loss,\n","            'val_loss': val_loss,\n","            'accuracy': report['accuracy'],\n","            'precision': report['1']['precision'],\n","            'recall': report['1']['recall'],\n","            'f1_score': report['1']['f1-score'],\n","            'auc': auc\n","        }\n","        metrics.append(row)\n","        print(f\"üìä Epoch {epoch}: F1={row['f1_score']:.2f}, AUC={auc:.2f}\")\n","\n","        if row['f1_score'] > best_f1:\n","            best_f1 = row['f1_score']\n","            torch.save(model.state_dict(), os.path.join(fold_dir, \"best_model.pth\"))\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","        if patience_counter >= PATIENCE:\n","            print(\"‚èπÔ∏è Early stopping\"); break\n","\n","    pd.DataFrame(metrics).to_csv(os.path.join(fold_dir, \"metrics.csv\"), index=False)\n","\n","    # üîç ROC + Confusion Matrix\n","    fpr, tpr, _ = roc_curve(trues, probs)\n","    plt.figure(); plt.plot(fpr, tpr, label=f\"AUC={auc:.2f}\"); plt.plot([0,1],[0,1],'k--')\n","    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"Fold {fold} ROC\"); plt.legend()\n","    plt.savefig(os.path.join(fold_dir, \"roc.png\")); plt.close()\n","\n","    cm = confusion_matrix(trues, preds)\n","    disp = ConfusionMatrixDisplay(cm, display_labels=['Non-T4', 'T4'])\n","    disp.plot(cmap='Blues'); plt.title(f\"Fold {fold} Confusion Matrix\")\n","    plt.savefig(os.path.join(fold_dir, \"confmat.png\")); plt.close()\n"],"metadata":{"id":"BDNiaMqGKRfK"},"execution_count":null,"outputs":[]}]}