{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNdroROVztTssbVUZeMSK2f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["3D CNN (5 layered) for classification of T4 and Non-T4 laryngeal cancer"],"metadata":{"id":"pa2rDh7yII_l"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Na5-7FxIIWg"},"outputs":[],"source":["!pip install torch torchvision monai torchio SimpleITK pandas scikit-learn matplotlib"]},{"cell_type":"code","source":["import os, numpy as np, pandas as pd, SimpleITK as sitk\n","import torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import classification_report, roc_curve, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n","from scipy.ndimage import zoom\n","from collections import Counter\n","import torchio as tio\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# CONFIG\n","IMAGE_DIR = \"/data/cropped_nrrds\"\n","LABEL_FILE = \"/data/annotations/LaryngealCT_metadata.xlsx\"\n","TARGET_SHAPE = (32, 96, 96)\n","BATCH_SIZE = 4\n","EPOCHS = 100\n","PATIENCE = 10\n","NUM_FOLDS = 5\n","LR = 1e-4\n","OUTPUT_DIR = \"outputs_3dcnn_augmented\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# CNN MODEL\n","class Deep3DCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv3d(1, 16, 3, padding=1), nn.BatchNorm3d(16), nn.ReLU(), nn.MaxPool3d(2),\n","            nn.Conv3d(16, 32, 3, padding=1), nn.BatchNorm3d(32), nn.ReLU(), nn.MaxPool3d(2),\n","            nn.Conv3d(32, 64, 3, padding=1), nn.BatchNorm3d(64), nn.ReLU(), nn.MaxPool3d(2),\n","            nn.Conv3d(64, 128, 3, padding=1), nn.BatchNorm3d(128), nn.ReLU(), nn.AdaptiveAvgPool3d(1)\n","        )\n","        self.fc = nn.Sequential(nn.Flatten(), nn.Linear(128, 2))\n","    def forward(self, x):\n","        return self.fc(self.conv(x))\n","\n","# FOCAL LOSS\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n","        super().__init__()\n","        self.alpha = alpha.float() if alpha is not None else None\n","        self.gamma = gamma\n","        self.reduction = reduction\n","\n","    def forward(self, inputs, targets):\n","        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n","        pt = torch.exp(-ce_loss)\n","        if self.alpha is not None:\n","            at = self.alpha[targets]\n","            loss = at * (1 - pt) ** self.gamma * ce_loss\n","        else:\n","            loss = (1 - pt) ** self.gamma * ce_loss\n","        return loss.mean() if self.reduction == 'mean' else loss.sum()\n","\n","# DATASET\n","class CTDataset(Dataset):\n","    def __init__(self, df, image_dir, target_shape, augment=False):\n","        self.df = df.reset_index(drop=True)\n","        self.image_dir = image_dir\n","        self.target_shape = target_shape\n","        self.augment = augment\n","        self.transform = tio.Compose([\n","            tio.RandomAffine(scales=(0.9, 1.1), degrees=10, translation=5, p=0.7),\n","            tio.RandomElasticDeformation(num_control_points=7, max_displacement=5.0, p=0.5),\n","            tio.RandomGamma(log_gamma=(-0.3, 0.3), p=0.5),\n","            tio.RandomNoise(p=0.3),\n","            tio.RandomFlip(axes=('LR',), p=0.5)\n","        ])\n","    def __len__(self):\n","        return len(self.df)\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        image = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(self.image_dir, row['Filename']))).astype(np.float32)\n","        image = np.clip(image, -300, 300)\n","        image = (image - image.mean()) / (image.std() + 1e-5)\n","        image = zoom(image, [t / s for t, s in zip(self.target_shape, image.shape)], order=1)\n","        image = np.expand_dims(image, 0)\n","        if self.augment:\n","            image = self.transform(tio.Image(tensor=image, type=tio.INTENSITY)).tensor\n","        return torch.tensor(image, dtype=torch.float32), torch.tensor(int(row['Label']))\n","\n","# MAIN TRAINING\n","df = pd.read_excel(LABEL_FILE)[['Study_ID', 'Label']].dropna()\n","df['Filename'] = df['Study_ID'].astype(str) + \"_0000.nrrd\"\n","df['Label'] = df['Label'].map({'Non_T4': 0, 'T4': 1})\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n","\n","for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['Label'])):\n","    print(f\"\\nðŸ” Fold {fold+1}/{NUM_FOLDS}\")\n","    train_df, val_df = df.iloc[train_idx], df.iloc[val_idx]\n","\n","    # Weighted Sampling\n","    class_counts = train_df['Label'].value_counts()\n","    class_weights = 1. / class_counts\n","    sample_weights = train_df['Label'].map(class_weights).values\n","    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n","\n","    train_loader = DataLoader(CTDataset(train_df, IMAGE_DIR, TARGET_SHAPE, augment=True), batch_size=BATCH_SIZE, sampler=sampler)\n","    val_loader = DataLoader(CTDataset(val_df, IMAGE_DIR, TARGET_SHAPE, augment=False), batch_size=BATCH_SIZE)\n","\n","    model = Deep3DCNN().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","    loss_fn = FocalLoss(alpha=torch.tensor([1.0, 4.0]).to(device), gamma=2.0)\n","    best_f1, patience_counter = 0, 0\n","    metrics = []\n","\n","    for epoch in range(1, EPOCHS + 1):\n","        model.train(); total_loss = 0\n","        for x, y in train_loader:\n","            optimizer.zero_grad()\n","            pred = model(x.to(device))\n","            loss = loss_fn(pred, y.to(device))\n","            loss.backward(); optimizer.step()\n","            total_loss += loss.item()\n","        train_loss = total_loss / len(train_loader)\n","\n","        # Validation\n","        model.eval(); val_loss, preds, trues = 0, [], []\n","        with torch.no_grad():\n","            for x, y in val_loader:\n","                out = model(x.to(device))\n","                val_loss += loss_fn(out, y.to(device)).item()\n","                preds.extend(torch.argmax(out, dim=1).cpu().tolist())\n","                trues.extend(y.tolist())\n","        val_loss /= len(val_loader)\n","\n","        report = classification_report(trues, preds, output_dict=True, zero_division=0)\n","        row = {\n","            'epoch': epoch,\n","            'train_loss': train_loss, 'val_loss': val_loss,\n","            'accuracy': report['accuracy'],\n","            'precision': report['1']['precision'],\n","            'recall': report['1']['recall'],\n","            'f1_score': report['1']['f1-score']\n","        }\n","        metrics.append(row)\n","        print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, \"\n","              f\"Acc={row['accuracy']:.2%}, Prec={row['precision']:.2f}, \"\n","              f\"Rec={row['recall']:.2f}, F1={row['f1_score']:.2f}\")\n","\n","        # Early stopping\n","        if row['f1_score'] > best_f1:\n","            best_f1 = row['f1_score']\n","            patience_counter = 0\n","            torch.save(model.state_dict(), f\"{OUTPUT_DIR}/fold_{fold+1}_best.pth\")\n","        else:\n","            patience_counter += 1\n","        if patience_counter >= PATIENCE:\n","            print(\"â¹ï¸ Early stopping triggered.\")\n","            break\n","\n","    # Save metrics\n","    pd.DataFrame(metrics).to_csv(f\"{OUTPUT_DIR}/fold_{fold+1}_metrics.csv\", index=False)\n","\n","    # ROC + Confusion Matrix\n","    model.load_state_dict(torch.load(f\"{OUTPUT_DIR}/fold_{fold+1}_best.pth\"))\n","    model.eval(); probs, y_true = [], []\n","    with torch.no_grad():\n","        for x, y in val_loader:\n","            out = model(x.to(device))\n","            probs.extend(torch.softmax(out, dim=1)[:, 1].cpu().tolist())\n","            y_true.extend(y.tolist())\n","    fpr, tpr, _ = roc_curve(y_true, probs)\n","    auc = roc_auc_score(y_true, probs)\n","    plt.figure(); plt.plot(fpr, tpr, label=f\"AUC={auc:.2f}\")\n","    plt.plot([0,1], [0,1], 'k--'); plt.legend()\n","    plt.title(f\"Fold {fold+1} ROC\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.grid()\n","    plt.savefig(f\"{OUTPUT_DIR}/fold_{fold+1}_roc.png\"); plt.close()\n","\n","    y_pred = [1 if p > 0.5 else 0 for p in probs]\n","    cm = confusion_matrix(y_true, y_pred)\n","    disp = ConfusionMatrixDisplay(cm, display_labels=['Non-T4', 'T4'])\n","    disp.plot(cmap='Blues'); plt.title(f\"Confusion Matrix Fold {fold+1}\")\n","    plt.savefig(f\"{OUTPUT_DIR}/fold_{fold+1}_confmat.png\"); plt.close()\n"],"metadata":{"id":"jKEdwWzVIdzX"},"execution_count":null,"outputs":[]}]}