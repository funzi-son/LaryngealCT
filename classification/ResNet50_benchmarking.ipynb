{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOyOAAkqmXOi+hRpK+6wKog"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["ResNet50 model for classification of T4 and Non-T4 laryngeal cancer"],"metadata":{"id":"xZkx9msVMoEY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FA3IJOLQMm-4"},"outputs":[],"source":["!pip install torch torchvision monai torchio pandas SimpleITK scikit-learn matplotlib"]},{"cell_type":"code","source":["!pip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0"],"metadata":{"id":"hErwcrsEM4D7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, numpy as np, pandas as pd, torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n","from sklearn.model_selection import StratifiedKFold\n","import torchio as tio\n","import SimpleITK as sitk\n","from scipy.ndimage import zoom\n","import matplotlib.pyplot as plt\n","import torchvision\n","\n","\n","\n","# CONFIG\n","IMAGE_DIR = \"/data/cropped_nrrds\"\n","LABEL_FILE = \"/data/annotations/LaryngealCT_metadata.xlsx\"\n","TARGET_SHAPE = (32, 96, 96)\n","BATCH_SIZE = 4\n","EPOCHS = 100\n","PATIENCE = 10\n","LR = 1e-4\n","NUM_FOLDS = 5\n","OUTPUT_DIR = \"/data/resnet50_cv_augmented\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# FOCAL LOSS\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n","        super().__init__()\n","        self.alpha = alpha.float() if alpha is not None else None\n","        self.gamma = gamma\n","        self.reduction = reduction\n","    def forward(self, inputs, targets):\n","        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n","        pt = torch.exp(-ce_loss)\n","        if self.alpha is not None:\n","            at = self.alpha[targets]\n","            loss = at * (1 - pt) ** self.gamma * ce_loss\n","        else:\n","            loss = (1 - pt) ** self.gamma * ce_loss\n","        return loss.mean() if self.reduction == 'mean' else loss.sum()\n","\n","# DATASET\n","class CTSubjectDataset(tio.SubjectsDataset):\n","    def __init__(self, df, augment=False):\n","        subjects = []\n","        self.df = df.reset_index(drop=True)\n","        for _, row in self.df.iterrows():\n","            img_path = os.path.join(IMAGE_DIR, row['Filename'])\n","            img = sitk.GetArrayFromImage(sitk.ReadImage(img_path)).astype(np.float32)\n","            img = np.clip(img, -300, 300)\n","            img = (img - img.mean()) / (img.std() + 1e-5)\n","            img = zoom(img, [t / s for t, s in zip(TARGET_SHAPE, img.shape)], order=1)\n","            img = np.expand_dims(img, 0)  # Shape: [1, D, H, W]\n","\n","            subject = tio.Subject(\n","                image=tio.ScalarImage(tensor=torch.tensor(img), type=tio.INTENSITY),\n","                label=int(row['Label'])\n","            )\n","            subjects.append(subject)\n","\n","        if augment:\n","            transform = tio.Compose([\n","                tio.RandomAffine(scales=(0.9, 1.1), degrees=10, translation=5, p=0.7),\n","                tio.RandomElasticDeformation(num_control_points=5, max_displacement=3.0, p=0.5),\n","                tio.RandomGamma(log_gamma=(-0.3, 0.3), p=0.5),\n","                tio.RandomNoise(p=0.3),\n","                tio.RandomFlip(axes=('LR',), p=0.5),\n","            ])\n","        else:\n","            transform = None\n","\n","        super().__init__(subjects, transform=transform)\n","\n","    def __getitem__(self, index):\n","        subject = super().__getitem__(index)\n","        image = subject['image'].data.float()  # shape: [1, D, H, W]\n","        label = torch.tensor(subject['label'])\n","        return image, label\n","\n","from monai.networks.nets import resnet50\n","\n","class ResNet50_3D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = resnet50(\n","            spatial_dims=3,\n","            n_input_channels=1,\n","            num_classes=2,\n","            pretrained=False\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","\n","# DATASET\n","df = pd.read_excel(LABEL_FILE)[['Study_ID', 'Label']].dropna()\n","df['Filename'] = df['Study_ID'].astype(str) + \"_0000.nrrd\"\n","df['Label'] = df['Label'].map({'Non_T4': 0, 'T4': 1})\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# CV\n","skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n","for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['Label']), 1):\n","    print(f\"\\n===== Fold {fold}/{NUM_FOLDS} =====\")\n","    fold_dir = os.path.join(OUTPUT_DIR, f\"fold_{fold}\")\n","    os.makedirs(fold_dir, exist_ok=True)\n","\n","    train_df, val_df = df.iloc[train_idx], df.iloc[val_idx]\n","    class_weights = 1. / train_df['Label'].value_counts()\n","    sample_weights = train_df['Label'].map(class_weights).values\n","    sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n","\n","    train_dataset = CTSubjectDataset(train_df, augment=True)\n","    val_dataset = CTSubjectDataset(val_df, augment=False)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n","\n","\n","    model = ResNet50_3D().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","    loss_fn = FocalLoss(alpha=torch.tensor([1.0, 4.0]).to(device), gamma=2.0)\n","\n","    best_f1, patience_counter = 0, 0\n","    metrics = []\n","\n","    for epoch in range(1, EPOCHS + 1):\n","        model.train(); total_loss = 0\n","        for x, y in train_loader:\n","            optimizer.zero_grad()\n","            out = model(x.to(device))\n","            loss = loss_fn(out, y.to(device))\n","            loss.backward(); optimizer.step()\n","            total_loss += loss.item()\n","        train_loss = total_loss / len(train_loader)\n","\n","        model.eval(); val_loss, preds, trues, probs = 0, [], [], []\n","        with torch.no_grad():\n","            for x, y in val_loader:\n","                out = model(x.to(device))\n","                val_loss += loss_fn(out, y.to(device)).item()\n","                probs.extend(torch.softmax(out, dim=1)[:, 1].cpu().tolist())\n","                preds.extend(torch.argmax(out, dim=1).cpu().tolist())\n","                trues.extend(y.tolist())\n","        val_loss /= len(val_loader)\n","\n","        report = classification_report(trues, preds, output_dict=True, zero_division=0)\n","        auc = roc_auc_score(trues, probs)\n","        row = {\n","            'epoch': epoch,\n","            'train_loss': train_loss,\n","            'val_loss': val_loss,\n","            'accuracy': report['accuracy'],\n","            'precision': report['1']['precision'],\n","            'recall': report['1']['recall'],\n","            'f1_score': report['1']['f1-score'],\n","            'auc': auc\n","        }\n","        metrics.append(row)\n","        print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Acc={row['accuracy']:.2%}, Prec={row['precision']:.2f}, Rec={row['recall']:.2f}, F1={row['f1_score']:.2f}, AUC={auc:.2f}\")\n","\n","        # Checkpoints\n","        if row['f1_score'] > best_f1:\n","            torch.save(model.state_dict(), os.path.join(fold_dir, \"best_f1.pth\"))\n","            best_f1 = row['f1_score']\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","        if patience_counter >= PATIENCE:\n","            print(\"⏹️ Early stopping triggered.\"); break\n","\n","    pd.DataFrame(metrics).to_csv(os.path.join(fold_dir, \"metrics.csv\"), index=False)"],"metadata":{"id":"HIVCQVNHM7wK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, torch, pandas as pd, numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, ConfusionMatrixDisplay\n","import torchio as tio\n","from torch.utils.data import DataLoader\n","import SimpleITK as sitk\n","from scipy.ndimage import zoom\n","from monai.networks.nets import resnet50\n","import torch.nn as nn\n","\n","# Config\n","IMAGE_DIR = \"/data/cropped_nrrds\"\n","LABEL_FILE = \"/data/annotations/LaryngealCT_metadata.xlsx\"\n","TARGET_SHAPE = (32, 96, 96)\n","BATCH_SIZE = 2\n","FOLD = 1 #change the fold number for each fold\n","OUTPUT_DIR = f\"/data/resnet50_cv_augmented/fold_{FOLD}\"\n","\n","# Dataset\n","class CTDataset(tio.SubjectsDataset):\n","    def __init__(self, df):\n","        subjects = []\n","        for _, row in df.iterrows():\n","            path = os.path.join(IMAGE_DIR, row['Filename'])\n","            img = sitk.GetArrayFromImage(sitk.ReadImage(path)).astype(np.float32)\n","            img = np.clip(img, -300, 300)\n","            img = (img - img.mean()) / (img.std() + 1e-5)\n","            img = zoom(img, [t / s for t, s in zip(TARGET_SHAPE, img.shape)], order=1)\n","            img = np.expand_dims(img, 0)\n","            subject = tio.Subject(image=tio.ScalarImage(tensor=torch.tensor(img)), label=int(row['Label']))\n","            subjects.append(subject)\n","        super().__init__(subjects)\n","\n","    def __getitem__(self, index):\n","        s = super().__getitem__(index)\n","        return s['image'].data.float(), torch.tensor(s['label'])\n","\n","# Model\n","class ResNet50_3D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = resnet50(spatial_dims=3, n_input_channels=1, num_classes=2, pretrained=False)\n","    def forward(self, x): return self.model(x)\n","\n","# Prepare\n","df = pd.read_excel(LABEL_FILE)[['Study_ID', 'Label']].dropna()\n","df['Filename'] = df['Study_ID'].astype(str) + \"_0000.nrrd\"\n","df['Label'] = df['Label'].map({'Non_T4': 0, 'T4': 1})\n","\n","metrics_df = pd.read_csv(os.path.join(OUTPUT_DIR, \"metrics.csv\"))\n","val_idx = metrics_df.index.tolist()\n","val_df = df.iloc[val_idx]\n","\n","val_loader = DataLoader(CTDataset(val_df), batch_size=BATCH_SIZE)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = ResNet50_3D().to(device)\n","model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, \"best_f1.pth\")))\n","model.eval()\n","\n","# Evaluation\n","probs, preds, trues = [], [], []\n","with torch.no_grad():\n","    for x, y in val_loader:\n","        out = model(x.to(device))\n","        prob = torch.softmax(out, dim=1)[:, 1]\n","        preds += torch.argmax(out, dim=1).cpu().tolist()\n","        probs += prob.cpu().tolist()\n","        trues += y.tolist()\n","\n","# Save plots\n","fpr, tpr, _ = roc_curve(trues, probs)\n","auc = roc_auc_score(trues, probs)\n","cm = confusion_matrix(trues, preds)\n","report = classification_report(trues, preds, output_dict=True)\n","\n","# ROC Curve\n","plt.figure()\n","plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.title(\"ROC - ResNet50\")\n","plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.grid(True); plt.legend()\n","plt.savefig(os.path.join(OUTPUT_DIR, \"roc_test.png\")); plt.close()\n","\n","# Confusion Matrix\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-T4\", \"T4\"])\n","disp.plot(cmap='Blues')\n","plt.title(\"Confusion Matrix - ResNet50\")\n","plt.savefig(os.path.join(OUTPUT_DIR, \"confmat_test.png\")); plt.close()\n","\n","print(\"✅ Evaluation completed and plots saved.\")\n","\n","#repeat the code for all five folds"],"metadata":{"id":"9zBO2J9bNM4D"},"execution_count":null,"outputs":[]}]}