{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGbMp3wncOd3yJ7qTIMyTh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["ResNet101 model for classification of T4 and Non-T4 laryngeal cancer"],"metadata":{"id":"MpQaVa_zOs5W"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"adgjZpNtOrt0"},"outputs":[],"source":["!pip install torch torchvision monai torchio pandas SimpleITK scikit-learn matplotlib"]},{"cell_type":"code","source":["!pip install monai==1.2.0 --quiet"],"metadata":{"id":"8uskyOI-O29D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, numpy as np, pandas as pd, torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import StratifiedKFold\n","from collections import Counter\n","import torchio as tio\n","import SimpleITK as sitk\n","from scipy.ndimage import zoom\n","from monai.networks.nets import ResNet\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torchio.data.image\")\n","\n","# ----------------------------- CONFIG ----------------------------- #\n","IMAGE_DIR = \"data/cropped_nrrds\"\n","LABEL_FILE = \"/data/annotations/LaryngealCT_metadata.xlsx\"\n","TARGET_SHAPE = (32, 96, 96)\n","BATCH_SIZE = 4\n","EPOCHS = 100\n","PATIENCE = 10\n","LR = 1e-4\n","NUM_FOLDS = 5\n","OUTPUT_BASE = \"/data/resnet101_cv_results\"\n","os.makedirs(OUTPUT_BASE, exist_ok=True)\n","\n","# ------------------------- FOCAL LOSS ----------------------------- #\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n","        super().__init__()\n","        self.alpha = alpha.float() if alpha is not None else None\n","        self.gamma = gamma\n","        self.reduction = reduction\n","    def forward(self, inputs, targets):\n","        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n","        pt = torch.exp(-ce_loss)\n","        if self.alpha is not None:\n","            at = self.alpha[targets]\n","            loss = at * (1 - pt) ** self.gamma * ce_loss\n","        else:\n","            loss = (1 - pt) ** self.gamma * ce_loss\n","        return loss.mean() if self.reduction == 'mean' else loss.sum()\n","\n","# ------------------------ Dataset with Aug ------------------------ #\n","class CTDataset(Dataset):\n","    def __init__(self, df, augment=False):\n","        self.df = df.reset_index(drop=True)\n","        self.augment = augment\n","        self.transform = tio.Compose([\n","            tio.RandomAffine(scales=(0.9, 1.1), degrees=10, translation=5, p=0.7),\n","            tio.RandomElasticDeformation(num_control_points=5, max_displacement=3.0, p=0.5),\n","            tio.RandomGamma(log_gamma=(-0.3, 0.3), p=0.5),\n","            tio.RandomNoise(p=0.3),\n","            tio.RandomFlip(axes=('LR',), p=0.5)\n","        ])\n","\n","    def __len__(self): return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        path = os.path.join(IMAGE_DIR, self.df.iloc[idx]['Filename'])\n","        img = sitk.GetArrayFromImage(sitk.ReadImage(path)).astype(np.float32)\n","        img = np.clip(img, -300, 300)\n","        img = (img - img.mean()) / (img.std() + 1e-5)\n","        img = zoom(img, [t / s for t, s in zip(TARGET_SHAPE, img.shape)], order=1)\n","        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)  # [1, D, H, W]\n","\n","        if self.augment:\n","            subject = tio.Subject(image=tio.ScalarImage(tensor=img))\n","            img = self.transform(subject)['image'].data\n","\n","        return img.clone().detach(), torch.tensor(int(self.df.iloc[idx]['Label']))\n","\n","# ---------------------- ResNet101 Model ---------------------- #\n","class ResNet101_3D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = ResNet(\n","            block=\"basic\",\n","            layers=(3, 4, 23, 3),\n","            block_inplanes=[64, 128, 256, 512],\n","            spatial_dims=3,\n","            n_input_channels=1,\n","            num_classes=2\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# -------------------------- Data Load ----------------------------- #\n","df = pd.read_excel(LABEL_FILE)[['Study_ID', 'Label']].dropna()\n","df['Filename'] = df['Study_ID'].astype(str) + \"_0000.nrrd\"\n","df['Label'] = df['Label'].map({'Non_T4': 0, 'T4': 1})\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n","for fold_id, (train_idx, val_idx) in enumerate(skf.split(df, df['Label']), 1):\n","    print(f\"\\n===== Fold {fold_id}/{NUM_FOLDS} =====\")\n","    fold_output = os.path.join(OUTPUT_BASE, f\"fold_{fold_id}\")\n","    os.makedirs(fold_output, exist_ok=True)\n","\n","    train_df, val_df = df.iloc[train_idx], df.iloc[val_idx]\n","    class_counts = train_df['Label'].value_counts()\n","    weights = 1. / class_counts\n","    sample_weights = train_df['Label'].map(weights).values\n","    sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n","\n","    train_loader = DataLoader(CTDataset(train_df, augment=True), batch_size=BATCH_SIZE, sampler=sampler)\n","    val_loader = DataLoader(CTDataset(val_df, augment=False), batch_size=BATCH_SIZE)\n","\n","    model = ResNet101_3D().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","    loss_fn = FocalLoss(alpha=torch.tensor([1.0, 4.0]).to(device), gamma=2.0)\n","\n","    best_f1, patience, metrics = 0, 0, []\n","    checkpoint_path = os.path.join(fold_output, \"checkpoint.pth\")\n","\n","    for epoch in range(1, EPOCHS + 1):\n","        model.train(); total_loss = 0\n","        for i, (x, y) in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            out = model(x.to(device))\n","            loss = loss_fn(out, y.to(device))\n","            loss.backward(); optimizer.step()\n","            total_loss += loss.item()\n","        train_loss = total_loss / len(train_loader)\n","\n","        model.eval(); val_loss, preds, trues = 0, [], []\n","        with torch.no_grad():\n","            for x, y in val_loader:\n","                out = model(x.to(device))\n","                val_loss += loss_fn(out, y.to(device)).item()\n","                preds.extend(torch.argmax(out, dim=1).cpu().tolist())\n","                trues.extend(y.tolist())\n","        val_loss /= len(val_loader)\n","\n","        report = classification_report(trues, preds, output_dict=True, zero_division=0)\n","        row = {\n","            'epoch': epoch,\n","            'train_loss': train_loss,\n","            'val_loss': val_loss,\n","            'accuracy': report['accuracy'],\n","            'precision': report['1']['precision'],\n","            'recall': report['1']['recall'],\n","            'f1_score': report['1']['f1-score']\n","        }\n","        metrics.append(row)\n","        print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Acc={row['accuracy']:.2%}, Prec={row['precision']:.2f}, Rec={row['recall']:.2f}, F1={row['f1_score']:.2f}\")\n","\n","        if row['f1_score'] > best_f1:\n","            best_f1 = row['f1_score']\n","            torch.save(model.state_dict(), os.path.join(fold_output, \"best_model.pth\"))\n","            patience = 0\n","        else:\n","            patience += 1\n","\n","        torch.save({\n","            'epoch': epoch,\n","            'model': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'best_f1': best_f1\n","        }, checkpoint_path)\n","\n","        if patience >= PATIENCE:\n","            print(\"‚èπÔ∏è Early stopping triggered.\")\n","            break\n","\n","    pd.DataFrame(metrics).to_csv(os.path.join(fold_output, \"metrics.csv\"), index=False)\n"],"metadata":{"id":"_NstUCppO5uV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import torchio as tio\n","import SimpleITK as sitk\n","from scipy.ndimage import zoom\n","from monai.networks.nets import ResNet\n","\n","# CONFIG\n","IMAGE_DIR = \"/data/cropped_nrrds\"\n","LABEL_FILE = \"/data/annotations/LaryngealCT_metadata.xlsx\"\n","OUTPUT_BASE = \"/data/resnet101_cv_results\"\n","TARGET_SHAPE = (32, 96, 96)\n","BATCH_SIZE = 4\n","NUM_FOLDS = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Dataset\n","class CTDataset(Dataset):\n","    def __init__(self, df):\n","        self.df = df.reset_index(drop=True)\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, idx):\n","        path = os.path.join(IMAGE_DIR, self.df.iloc[idx]['Filename'])\n","        img = sitk.GetArrayFromImage(sitk.ReadImage(path)).astype(np.float32)\n","        img = np.clip(img, -300, 300)\n","        img = (img - img.mean()) / (img.std() + 1e-5)\n","        img = zoom(img, [t / s for t, s in zip(TARGET_SHAPE, img.shape)], order=1)\n","        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)\n","        return img, int(self.df.iloc[idx]['Label'])\n","\n","# Model\n","class ResNet101_3D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = ResNet(\n","            block=\"basic\",\n","            layers=(3, 4, 23, 3),\n","            block_inplanes=[64, 128, 256, 512],\n","            spatial_dims=3,\n","            n_input_channels=1,\n","            num_classes=2\n","        )\n","    def forward(self, x): return self.model(x)\n","\n","# Load label file\n","df = pd.read_excel(LABEL_FILE)[['Study_ID', 'Label']].dropna()\n","df['Filename'] = df['Study_ID'].astype(str) + \"_0000.nrrd\"\n","df['Label'] = df['Label'].map({'Non_T4': 0, 'T4': 1})\n","\n","# K-Fold Evaluation\n","from sklearn.model_selection import StratifiedKFold\n","skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n","for fold_id, (_, val_idx) in enumerate(skf.split(df, df['Label']), 1):\n","    print(f\"üîç Evaluating Fold {fold_id}\")\n","    val_df = df.iloc[val_idx]\n","    val_loader = DataLoader(CTDataset(val_df), batch_size=BATCH_SIZE)\n","\n","    fold_dir = os.path.join(OUTPUT_BASE, f\"fold_{fold_id}\")\n","    model = ResNet101_3D().to(device)\n","    model.load_state_dict(torch.load(os.path.join(fold_dir, \"best_model.pth\")))\n","    model.eval()\n","\n","    probs, preds, trues = [], [], []\n","    with torch.no_grad():\n","        for x, y in val_loader:\n","            out = model(x.to(device))\n","            soft = torch.softmax(out, dim=1)\n","            probs.extend(soft[:, 1].cpu().numpy())\n","            preds.extend(torch.argmax(soft, dim=1).cpu().numpy())\n","            trues.extend(y.numpy())\n","\n","    # AUC\n","    auc = roc_auc_score(trues, probs)\n","    with open(os.path.join(fold_dir, \"auc.txt\"), \"w\") as f:\n","        f.write(f\"AUC: {auc:.4f}\")\n","\n","    # ROC Curve\n","    fpr, tpr, _ = roc_curve(trues, probs)\n","    plt.figure()\n","    plt.plot(fpr, tpr, label=f\"AUC={auc:.2f}\")\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n","    plt.title(f\"Fold {fold_id} ROC\"); plt.legend()\n","    plt.savefig(os.path.join(fold_dir, \"roc.png\"))\n","    plt.close()\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(trues, preds)\n","    disp = ConfusionMatrixDisplay(cm, display_labels=['Non-T4', 'T4'])\n","    disp.plot(cmap='Blues')\n","    plt.title(f\"Fold {fold_id} Confusion Matrix\")\n","    plt.savefig(os.path.join(fold_dir, \"confmat.png\"))\n","    plt.close()\n"],"metadata":{"id":"nhc36sMcPO75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","base_dir = \"/data/resnet101_cv_results\"\n","num_folds = 5\n","summary_rows = []\n","\n","for fold in range(1, num_folds + 1):\n","    metrics_path = os.path.join(base_dir, f\"fold_{fold}\", \"metrics.csv\")\n","    if not os.path.exists(metrics_path):\n","        continue\n","    df = pd.read_csv(metrics_path)\n","    best_epoch = df.loc[df[\"f1_score\"].idxmax()]\n","    summary_rows.append({\n","        \"Fold\": fold,\n","        \"Epoch\": int(best_epoch[\"epoch\"]),\n","        \"Accuracy\": best_epoch[\"accuracy\"],\n","        \"Precision\": best_epoch[\"precision\"],\n","        \"Recall\": best_epoch[\"recall\"],\n","        \"F1-score\": best_epoch[\"f1_score\"],\n","        \"AUC\": best_epoch.get(\"auc\", None)\n","    })\n","\n","summary_df = pd.DataFrame(summary_rows)\n","display(summary_df)\n","\n","melted = summary_df.melt(id_vars=[\"Fold\"], value_vars=[\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"AUC\"])\n","plt.figure(figsize=(10, 6))\n","sns.barplot(data=melted, x=\"variable\", y=\"value\", hue=\"Fold\")\n","plt.title(\"ResNet101 Fold-wise Performance\")\n","plt.ylabel(\"Score\")\n","plt.ylim(0, 1)\n","plt.legend(title=\"Fold\")\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"kgzrGsonPg5q"},"execution_count":null,"outputs":[]}]}